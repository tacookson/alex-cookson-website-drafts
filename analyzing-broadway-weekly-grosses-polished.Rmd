---
title: Analyzing Broadway weekly grosses
author: Alex Cookson
date: '2020-04-22'
slug: analyzing-broadway-weekly-grosses
categories: []
tags: ["data exploration", "data cleaning", "time series data"]
description: ''
topics: []
---  
\  

I love musicals! Who doesn't?! That feeling when the lits dim at the beginning of the show. The intermission conversation (post-bathroom!) of which songs you enjoyed the most. Spending the rest of the week (maybe month?) humming your favourites to the annoyance of everyone around you.

What's that? ***Les Misérables*** is *obviously* the best musical? I know, I know. I mean, *Hamilton* is good and all that, and it deserves praise, but it's no *Les Mis* (don't @ me).

Speaking of *Hamilton*, have you ever wondered how much money it and other Broadway shows have made? Or whether any other shows have come even close to *Hamilton*'s [record-breaking](https://variety.com/2017/legit/news/hamilton-ticket-prices-1202648756/) ticket prices? We're going to investigate exactly those questions today:

- **What are the most successful Broadway shows?**
- **How have ticket prices changed over time?**  
\  


## Setup

First, we'll load the `tidyverse` and other useful packages:

- `lubridate` for working with dates
- `scales` for making numbers pretty (e.g., turning 5e6 into 5,000,000 or 5M)
- `fishualize` for some of my favourite ggplot colour palettes (and [recently updated](https://github.com/nschiett/fishualize) to version 0.2.0)
- `extrafont` for using additional font options for graphs  
\  

Then we'll import our data. We're using weekly box office grosses from [Playbill](https://www.playbill.com/grosses) and Consumer Price Index (CPI) data from the [U.S. Bureau of Labor Statistics](https://www.bls.gov/). If you want more details on the data or the collection process, take a look at the [README](https://github.com/tacookson/data/tree/master/broadway-grosses) for it on GitHub.

```{r setup-and-import, warning = FALSE, message = FALSE}
library(tidyverse)
library(lubridate)
library(scales)
library(fishualize)
library(extrafont)

theme_set(theme_light())

# Adding guess_max = 10000 show readr gets the column specifications right
grosses_raw <- readr::read_csv("https://raw.githubusercontent.com/tacookson/data/master/broadway-grosses/grosses.csv",
                            guess_max = 10000)
cpi_raw <- readr::read_csv("https://raw.githubusercontent.com/tacookson/data/master/broadway-grosses/cpi.csv")
```


## Data inspection

Our main dataset is `grosses_raw`. What treasure lies inside?

```{r inspect-grosses}
glimpse(grosses_raw)
```

We have four types of data:

1. Dates, like the week in question and the week number of the Broadway season (which starts after the Tony Awards in early June)
2. Show and theatre data, like the name of the show and the theatre capacity
3. Performance data, like the number of performances in a given week, the seats sold, and the percent capacity for the week
4. Money data, like ticket prices, box office grosses, and a show's potential weekly gross

I've compiled a [data dictionary](https://github.com/tacookson/data/tree/master/broadway-grosses) if you want the details of specific fields.  
\  

The second dataset, `cpi_raw` is a helper dataset to adjust dollar figures for inflation. Our data spans 35 years and $50 in 1985 goes farther than it does in 2020!

```{r inspect-cpi}
glimpse(cpi_raw)
```

These are straightforward: the value of the Consumer Price Index (CPI) for each month since January 1985. There are *tons* of different CPI measures, but I used [All items less food and energy in U.S. city average, all urban consumers, seasonally adjusted](https://beta.bls.gov/dataViewer/view/timeseries/CUSR0000SA0L1E). I think it gets us closest to the purchasing power of a New York City theatre-goer.  
\  


### Data cleaning

Before we can answer our questions, we need to some data cleaning. Specifically, we need to **identify missing values** and **add a field about what week of a run a show is on** (there's a snag that makes this last one tricky -- keep reading).  
\  

#### Identify missing values

Don't blindly trust data that you didn't collect yourself. A lot of the time, a quick investigation will shine a light on quirks that could mess up your analysis down the line and this data isn't any different. There are a few circumstances where I'm going to change values to `NA` (missing values):

- Measures like `weekly_gross` and `seats_sold` sometimes have values of zero for weeks where there were no performances
- These measures also sometimes have zeros for weeks when there *were* performances -- I checked this out and it seems to be data missing from the source
- `top_ticket_price` sometimes has values in weeks with no performances

(There is the possibility that the data showing weeks without any performances is wrong itself, but based on some spot-checking and research, I'm comfortable making the assumption the we're just dealing with missing or wonky data from the source.)

```{r implicit-missing-values}
grosses_fixed_missing <- grosses_raw %>%
  # Turn metrics into missing values if there were no shows
  # OR if metrics have a value of zero
  mutate_at(vars(weekly_gross:pct_capacity),
            ~ ifelse(performances + previews == 0 | . == 0, NA, .))
```  
\  


#### Adding week of show's run

Remember when I said this one's tricky? There are two reasons why. To illustrate the first, let's look at *Les Misérables*. Here's a quick graph of seats sold by week (with a bonus illustration of using `scale_x_date()` to adjust date axis labels).

```{r les-mis-seats-sold, warning = FALSE, message = FALSE, fig.align = 'center', fig.width = 8, fig.asp = 0.618}
grosses_fixed_missing %>%
  filter(show == "Les Miserables") %>%
  ggplot(aes(week_ending, seats_sold)) +
  geom_col() +
  scale_x_date(date_breaks = "5 years", date_labels = "%Y") +
  labs(title = "Two-four-six-oh-what??")
```

Why are there two big gaps? Well, *Les Misérables*, like many Broadway shows, has had multiple runs:

1. 1987-2003
2. 2006-2008
3. 2014-2016

But they all have the **same show name** in our data. So when figuring out which week of a run a show is in, we can't just count the number of weeks since it first showed up in our data. We also need to figure out whether a show has started a fresh new run. I don't want to look that up manually for \*checks notes\* `r comma(n_distinct(grosses_raw$show))` shows, so we need a heuristic to do that.

I'm going to assume that the first time a show appears is its first run. (This isn't technically true for shows that opened and closed before our dataset starts in 1985, like *The King and I*, but it's close enough for our purposes.) I'm also going to assume that a show has started a new run if it has been more than 90 days -- about 12 weeks -- since the previous time it appeared in the data. I chose 90 days because it's long enough to account for shows that shut down briefly, which they sometimes to for things like moving to a new theatre. It's also short enough that it won't accidentally consider seasonal productions, which might appear in consecutive years, the same run.

Fortunately, we can do that in a few lines of code:

1. Grouping by show, for each observation, check whether it is the first time it appears or whether it is more than 90 days since the previous week in the data. This will return a logical value `TRUE` or `FALSE`, which indicate the first week of a new run.
2. Use the cumulative sum function `cumsum()` to determine the run number. `R` coerces `TRUE` to one and `FALSE` to zero, so `cumsum()` acts as a counter that only increases when it hits a new run's first week (which we calculated in step 1).
3. Group by show *and* run number and use `row_number()` which counts the rows as they appear in the data. Since each show and run is its own group, you get the week of the run!

```{r fix-run-weeks-1}
grosses_clean_temp <- grosses_fixed_missing %>%
  group_by(show) %>%
  arrange(week_ending) %>%
  mutate(run_number = cumsum(row_number() == 1 |
                               week_ending - lag(week_ending) > 90)) %>%
  group_by(show, run_number) %>%
  mutate(week_of_run = row_number()) %>%
  ungroup()
```  
\  

But remember when I said there were **two** reasons this one's tricky? Here's the second reason.

```{r fix-run-weeks-2}
pre_1985_starts <- readr::read_csv("https://raw.githubusercontent.com/tacookson/data/master/broadway-grosses/pre-1985-starts.csv")

calculate_weeks_since_start <- function(x) {
  as.integer(pmax(1, difftime("1985-06-09", x, units = "weeks")))
}

pre_1985_starts_calculated <- grosses_clean_temp %>%
  group_by(show, run_number) %>%
  filter(min(week_ending) == "1985-06-09") %>%
  ungroup() %>%
  select(week_ending, show) %>%
  left_join(pre_1985_starts, by = "show") %>%
  group_by(show) %>%
  mutate(week_of_run_originals = calculate_weeks_since_start(start_date) + row_number()) %>%
  ungroup() %>%
  select(week_ending, show, week_of_run_originals)

grosses_clean <- grosses_clean_temp %>%
  left_join(pre_1985_starts_calculated, by = c("show", "week_ending")) %>%
  mutate(week_of_run = coalesce(week_of_run_originals, week_of_run)) %>%
  select(-week_of_run_originals)
```


### Money

Cleaning CPI inflation data

```{r cpi-index-jan-2020}
cpi <- cpi_raw %>%
  mutate(jan_2020_dollars = cpi[year_month == "2020-01-01"] / cpi)
```


Adjusting dollar amounts to be in Jan 2020 dollars

```{r grosses-2020-dollars}
real_grosses <- grosses_clean %>%
  mutate(year_month = floor_date(week_ending, unit = "month")) %>%
  left_join(cpi, by = "year_month") %>%
  mutate_at(
    vars(
      weekly_gross_overall,
      weekly_gross,
      potential_gross,
      avg_ticket_price,
      top_ticket_price
    ),
    ~ . * jan_2020_dollars
  ) %>%
  select(-year_month:-jan_2020_dollars)
```


Cumulative gross over week of run

```{r cumulative-gross, warning = FALSE, message = FALSE, fig.align = 'center', fig.width = 12, fig.asp = 0.618}
cumulative_grosses_by_year <- real_grosses %>%
  mutate(show_and_run = paste0(show, " (Run ", run_number, ")"),
         year_of_run = week_of_run / 52) %>%
  group_by(show_and_run) %>%
  mutate(
    weekly_gross = coalesce(weekly_gross, 0),
    cumulative_gross = cumsum(weekly_gross)
  ) %>%
  ungroup() %>%
  group_by(show_and_run) %>%
  mutate(show_label = ifelse(
    year_of_run == max(year_of_run),
    paste0(" ", show),
    NA_character_
  )) %>%
  ungroup() %>%
  mutate(show_and_run = fct_reorder(show_and_run, year_of_run, .fun = max))

top_10_grossing <- cumulative_grosses_by_year %>%
  group_by(show_and_run) %>%
  summarise(show_total_gross = sum(weekly_gross)) %>%
  ungroup() %>%
  top_n(10, wt = show_total_gross) %>%
  pull(show_and_run)

cumulative_grosses_by_year %>%
  filter(show_and_run %in% top_10_grossing) %>%
  ggplot(aes(year_of_run, cumulative_gross, col = show_and_run)) +
  geom_line(size = 0.5) +
  geom_label(
    aes(label = show_label),
    size = 3,
    family = "Bahnschrift",
    fontface = "bold",
    hjust = 0,
    vjust = 0,
    label.size = NA,
    label.padding = unit(0.01, "lines"),
    label.r = unit(0.5, "lines")
  ) +
  scale_x_continuous(breaks = seq(0, 40, 5)) +
  scale_y_continuous(labels = label_dollar(scale = 1 / 1e6, suffix = "M")) +
  scale_colour_fish(option = "Epibulus_insidiator",
                    discrete = TRUE,
                    direction = 1) +
  expand_limits(x = 40) +
  labs(
    title = "Could Hamilton overtake The Lion King in...20 years?",
    subtitle = paste0("Cumulative box office receipts (Jan. 2020 dollars) for top 10 grossing shows since 1985"),
    caption = paste0("Source: Playbill\n",
                     "Note: Partial data for Cats, which started in 1982 (this data begins in 1985)"),
    x = "Year of run",
    y = ""
  ) +
  theme(
    legend.position = "none",
    text = element_text(family = "Bahnschrift"),
    panel.grid.minor = element_blank()
  )
```


Visualize progression of average top ticket prices

```{r top-ticket-prices}
top_tickets <- grosses_clean %>%
  mutate(year = year(week_ending)) %>%
  filter(year >= 1996,
         !is.na(top_ticket_price)) %>%
  group_by(year, show) %>%
  summarise(avg_ticket_price = mean(avg_ticket_price, na.rm = TRUE),
            avg_top_ticket_price = mean(top_ticket_price, na.rm = TRUE)) %>%
  mutate(annotated = (show == "The Producers" & between(year, 2002, 2003)) | show == "Manilow on Broadway") %>%
  ungroup() %>%
  mutate(is_hamilton = show == "Hamilton")

avg_top_tickets_by_year <- top_tickets %>%
  group_by(year) %>%
  summarise(avg_top_ticket_price = mean(avg_top_ticket_price))
  
top_tickets %>%
  ggplot(aes(year, avg_top_ticket_price)) +
  geom_jitter(data = top_tickets %>% filter(!annotated, !is_hamilton),
              position = position_jitter(width = 0.2),
              shape = 19,
              size = 2,
              col = "grey80",
              alpha = 0.5) +
  geom_point(data = top_tickets %>% filter(annotated),
             size = 2,
             col = "black") +
  geom_point(data = top_tickets %>% filter(is_hamilton),
             col = "#fc9d26",
             size = 4) +
  geom_line(data = avg_top_tickets_by_year,
            size = 1,
            col = "darkblue") +
  scale_x_continuous(breaks = seq(1996, 2020, 2)) +
  scale_y_continuous(breaks = seq(0, 1000, 100),
                     labels = dollar_format()) +
  annotate("text", x = 2018.5, y = 880, label = "Hamilton", col = "#fc9d26") +
  annotate("curve", x = 2011, y = 660, xend = 2012.95, yend = 695, curvature = 0.3, arrow = arrow(length = unit(2, "mm"))) +
  annotate("text", x = 2010.9, y = 665, label = "Manilow on Broadway", hjust = "right") +
  annotate("curve", x = 2003.5, y = 540, xend = 2002.05, yend = 485, curvature = 0.3, arrow = arrow(length = unit(2, "mm"))) +
  annotate("curve", x = 2003.5, y = 540, xend = 2003, yend = 485, curvature = 0.3, arrow = arrow(length = unit(2, "mm"))) +
  annotate("text", x = 2003.5, y = 540, label = "The Producers", hjust = "left") +
  labs(title = "A premium Broadway experience has become much pricier",
       subtitle = "(Especially if you're seeing Hamilton) Points show the average top ticket price for each show, by year",
       x = "",
       y = "") +
  theme(panel.grid.minor = element_blank())
```


Visualize progression of average average ticket prices

In 1985, the average Broadway ticket cost \$65. In 2020 (so far), it was \$119.

```{r avg-ticket-prices}
avg_tickets <- real_grosses %>%
  mutate(year = year(week_ending)) %>%
  filter(!is.na(avg_ticket_price)) %>%
  group_by(year, show) %>%
  summarise(avg_ticket_price = mean(avg_ticket_price, na.rm = TRUE),
            performances = sum(performances)) %>%
  ungroup()

avg_tickets_by_year <- avg_tickets %>%
  group_by(year) %>%
  summarise(avg_ticket_price = weighted.mean(avg_ticket_price, w = performances))
  
avg_tickets %>%
  ggplot(aes(year, avg_ticket_price)) +
  geom_jitter(position = position_jitter(width = 0.2),
              shape = 19,
              size = 2,
              col = "grey80",
              alpha = 0.5) +
  geom_line(data = avg_tickets_by_year,
            size = 1,
            col = "darkblue") +
  scale_y_continuous(labels = dollar_format()) +
  labs(title = "The cost of a Broadway experience has doubled in the past 35 years",
       subtitle = "Inflation-adjusted average ticket prices (Jan. 2020 dollars)",
       x = "",
       y = "") +
  theme(panel.grid.minor = element_blank())
```