---
title: "Empirical Bayes Estimation"
author: "Alex Cookson"
date: "12/06/2020"
output: html_document
---

Tags: Bayesian inference, normalization, rescaling, animated graphs

Ratings sites -- like Rotten Tomatoes and IMDb for movies or Goodreads for books -- are annoying. They each seem to have their norms where the same rating means different things on different sites. A rating of 60% on one site might be good, but 6/10 (equivalent to 60%) on another site might be terrible. So you need to do some extra mental work to set your expectations based on the specific site you're on.

Ratings also often don't use their full scale. If you've bought something from Amazon, you're probably familiar with this. The theoretical lower bound of ratings might be 1 star, but in reality, ratings rarely go below 3 stars. So you need to do a *second bit* of extra mental work to re-calculate the fact that "3 stars" *really* means "1 star".

Sometimes you do see an item with an unambiguously good or bad score, like 5 stars or 1 star...but then you see that only one or two people have rated it. So you need to do a *third bit* of extra mental work to take number of ratings into account, since an item with 4.8 stars and 10,000 ratings is probably better than an item with 5.0 stars and 2 ratings.

The article [Whose ratings should you trust?](https://www.freecodecamp.org/news/whose-reviews-should-you-trust-imdb-rotten-tomatoes-metacritic-or-fandango-7d1010c6cf19/) by Alex Olteanu does a good job of capturing my frustration. I *want* ratings to look like this:

### Picture of normal

But ratings *actually* look like this:

### Picture of actual ratings


In this post, I will "fix" some of these ratings problems:

- Empirical Bayes estimation to address items with few ratings
- Normalizing and re-scaling to get ratings to look how I want them to look (and use their full scale)


We will use a dataset of almost 10,000 children's books that have been rated from 1-5 stars.


## Setup

First, we'll load our packages and import the data. In addition to the `tidyverse`, we'll use:

- `scales` for nicely-formatted numbers and useful re-scaling functions
- `stats4` and `broom` to help us with our empirical Bayes estimation
- `extrafont` and `fishualize` to make our graphs look nice
- `gganimate` to visualize what exactly empirical Bayes estimation does to the ratings

```{r setup-and-import, warnings = FALSE, message = FALSE}
library(tidyverse)
library(scales)
library(stats4)
library(broom)
library(extrafont)
library(fishualize)
library(gganimate)

theme_set(theme_light())

books <- read_tsv("https://raw.githubusercontent.com/tacookson/data/master/childrens-book-ratings/childrens-books.txt") %>%
  # Select only fields we're using (book identifiers, author, and ratings)
  select(isbn:author, rating:rating_1)
```  
\  

We're not doing any exploratory data analysis or feature engineering, so our data is simple: the book's ISBN and title, the author, the raw overall rating, and the number of people who rated the book at each star level.

```{r data-inspection}
books %>%
  glimpse()
```  
\  


## What do the raw ratings look like?

Before fixing the ratings, we need to know what we're fixing! Let's look at the distribution of ratings:

```{r original-rating-distribution, fig.align = 'center', fig.width = 8, fig.asp = 0.7}
books %>%
  filter(!is.na(rating)) %>%
  ggplot(aes(rating)) +
  geom_histogram(binwidth = 0.1, fill = "#461220", alpha = 0.8) +
  expand_limits(x = 1) +
  labs(title = "Empirically, an \"average\" book has a 4-star rating",
       subtitle = "And almost no books have fewer than 3 stars",
       x = "Star rating",
       y = "Number of books") +
  theme(text = element_text(family = "Bahnschrift"),
        plot.title = element_text(size = 18),
        axis.text = element_text(size = 16))
```

This is fairly typical of crowd-sourced ratings:

1. **Spike at the maximum** 5-star rating
1. **Ratings concentrated** in one part of the range, with almost all books between 3 and 5 stars
1. **High average rating**, with a mean of `r comma(mean(books$rating, na.rm = TRUE), accuracy = 0.01)` stars

I find that all three issues come up in rating systems like this, but let's focus on point 1 for now. What are these amazing 5-star books? Let's look at one:

```{r five-star-books}
# For reproducability
set.seed(1867)

# There are many 5-star books, so we will use sample_n() to get just one
books %>%
  select(title, rating:rating_1) %>%
  filter(rating == 5) %>%
  sample_n(1)
```

One of them is a book called [*Pickles and Cake*](https://books.google.ca/books/about/Pickles_and_Cake.html?id=t4UljwEACAAJ&redir_esc=y). This could be an amazing book -- three people liked it enough to give it a 5-star rating. But how does it stack up against books where more people have weighed in? Let's compare it to the top-rated book with at least, say, 10,000 ratings:

```{r highest-rated-book}
books %>%
  select(title, rating:rating_1) %>%
  filter(rating_count >= 1e4) %>%
  top_n(1, wt = rating)
```

That book is [*It's a Magical World*](https://calvinandhobbes.fandom.com/wiki/It%27s_a_Magical_World) by the peerless Bill Watterson, creator of Calvin & Hobbes, with a rating of 4.76. It has a lower rating than *Pickles and Cake*'s 5 stars, so is *Pickles and Cake* the better book? Possibly, but I'm hesitant to make that conclusion. *It's a Magical World* has more than 20,000 5-star ratings, while *Pickles and Cake* has three. I'd want to see more people to weigh in on *Pickles and Cake* before making that call.

So we need more data to make a judgement about *Pickles and Cake*. But we don't *have* more data. This illustrates a variation of the [*cold start problem*](https://blog.dataiku.com/tackling-the-cold-start-problem), a common issue when building recommendation engines: a new book will have few or no ratings, so we can't decide whether it's good, bad, or average.

We could wait for more ratings to roll in, but this approach has two issues. First, we'd need to set a threshold for how many ratings is "enough", which is kind of arbitrary. Second, by setting a threshold, we would be ignoring useful data that we have about a book until it reaches that threshold. Say we decide that books need 100 ratings before we trust the star rating. If a book had 99 ratings, we'd say to ourselves, "Welp, no idea what to think about this one!" But we have more information on a book with 99 ratings than a book with 10 ratings. Or a book with 0 ratings.

Fortunately, statistics can help us. **We can initially assume a book is average until we get enough data to suggest otherwise.** There are two important pieces to that sentence:

1. *We can initially assume a book is average*: This initial assumption is a **Bayesian prior**, which is what we believe before we have any data. I think this is a reasonable assumption. If I learned of a new book and knew literally nothing about it, I wouldn't assume it's amazing or terrible. I'd assume it's average until I learned more about it. (For a fun introduction to the topic, see Will Kurt's blog post [*Han Solo and Bayesian Priors*](https://www.countbayesie.com/blog/2015/2/18/hans-solo-and-bayesian-priors).)
2. *until we get enough data to suggest otherwise*: The initial assumption is just that -- an *initial* assumption. As more people rate a book, we'll start to trust those ratings more than our assumption. As a book gets more and more ratings, our initial assumption will have less influence on what we think a book's true rating is.

This entire approach is called **shrinkage**, which David Robinson defines very well in [*Introduction to Empirical Bayes*](http://varianceexplained.org/r/empirical-bayes-book/):

> [Shrinkage is] the process of moving all our estimates towards the average. How much it moves these estimates depends on how much evidence we have: if we have very little evidence [like three ratings for *Pickles and Cake*] we move it a lot, if we have a lot of evidence [like 20,000 ratings for *It's a Magical World*] we move it only a little. Thatâ€™s shrinkage in a nutshell: *Extraordinary outliers require extraordinary evidence*.


### MLE

```{r rating-pct-distribution, fig.align = 'center', fig.width = 8, fig.asp = 0.4}
rating_pct <- books %>%
  filter(rating_count > 0) %>%
  mutate_at(vars(rating_5:rating_1), ~ . / rating_count) %>%
  # Filter for books with at least 500 reviews
  filter(rating_count > 500) %>%
  pivot_longer(cols = rating_5:rating_1,
               names_to = "rating_level",
               values_to = "pct_of_ratings") %>%
  # Use Unicode symbol for full star (U+2605) and empty star (U+2606) as facet titles
  mutate(rating_num = parse_number(rating_level),
         stars_label = paste0(strrep("\U2605", rating_num),
                              strrep("\u2606", 5 - rating_num)),
         stars_label = fct_reorder(stars_label, rating_num)) %>%
  select(-rating_num)

rating_pct %>%
  ggplot(aes(pct_of_ratings)) +
  geom_histogram(binwidth = 0.025, fill = "#461220", alpha = 0.8) +
  facet_wrap(~ stars_label, nrow = 1) +
  scale_x_continuous(labels = label_percent()) +
  labs(title = "Proportions of ratings at each star level have their own distributions",
       x = "% of ratings",
       y = "Number of books") +
  theme(text = element_text(family = "Bahnschrift"),
        axis.text = element_text(size = 9),
        strip.text = element_text(size = 20, colour = "black"),
        strip.background = element_blank(),
        panel.grid.minor = element_blank())
```


```{r dirichlet-multinomial, message = FALSE}
# Create a matrix to feed our MLE of Dirichlet-Multinomial
rating_matrix <- books %>%
  filter(rating_count > 500) %>%
  select(rating_5:rating_1) %>%
  as.matrix()

# Fit a Dirichlet Multinomial distribution
dm_fit <- DirichletMultinomial::dmn(rating_matrix, 1)

# Write a function to tidy DMN object (which dm_fit is)
# Function from http://varianceexplained.org/r/empirical-bayes-book/
tidy.DMN <- function(x, ...) {
  ret <- as.data.frame(x@fit)
  as_tibble(fix_data_frame(ret, c("conf.low", "estimate", "conf.high")))
}

# Tidy the DMN fit
dm_params <- tidy(dm_fit)
```

```{r dirichlet-parameters}
# Get parameters into a useful format
par <- dm_params %>%
  separate(term, into = c("constant", "rating_stars"), sep = "_", convert = TRUE) %>%
  select(rating_stars,
         prior_ratings = estimate)

# Calculate total prior ratings and mean (used for graphing)
par_total <- sum(par$prior_ratings)
par_mean <- par %>%
  summarise(prior_rating = sum(rating_stars * prior_ratings) / sum(prior_ratings)) %>%
  pull(prior_rating)
```

```{r dirichlet-histograms, fig.align = 'center', fig.width = 8, fig.asp = 0.4}
dirichlet_density <- dm_params %>%
  select(rating_level = term, estimate) %>%
  crossing(pct_of_ratings = seq(0, 0.8, by = 0.0125)) %>%
  mutate(density = dbeta(pct_of_ratings, estimate, par_total - estimate)) %>%
  # Use Unicode symbol for full star (U+2605) and empty star (U+2606) as facet titles
  mutate(rating_num = parse_number(rating_level),
         stars_label = paste0(strrep("\U2605", rating_num),
                              strrep("\U2606", 5 - rating_num)),
         stars_label = fct_reorder(stars_label, rating_num)) %>%
  select(-rating_num)

rating_pct %>%
  ggplot(aes(pct_of_ratings)) +
  geom_histogram(aes(y = ..density..), binwidth = 0.025, fill = "#461220", alpha = 0.8) +
  geom_area(data = dirichlet_density, aes(y = density), fill = "#778DA9", alpha = 0.7) +
  facet_wrap(~ stars_label, nrow = 1) +
  scale_x_continuous(labels = label_percent()) +
  labs(title = "Maximum-Likelihood Estimates fit the data fairly well",
       subtitle = "Red histogram = Actual distribution | Blue curve = MLE fit",
       x = "% of ratings",
       y = "Density") +
  theme(text = element_text(family = "Bahnschrift"),
        axis.text = element_text(size = 9),
        strip.text = element_text(size = 20, colour = "black"),
        strip.background = element_blank(),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_blank())
```

Observations:

- Fairly good fits overall
- MLE fit under-estimates the spread of the 5-star ratings (blue density is narrower than the empirical histogram)



```{r calculate-empirical-bayes-rating, message = FALSE}
# Calculate empirical Bayes rating using our prior
books_eb <- books %>%
  pivot_longer(rating_5:rating_1,
               names_to = c("rating_stars"),
               names_pattern = "rating_(.*)",
               names_transform = list(rating_stars = as.integer),
               values_to = "ratings") %>%
  left_join(par, by = "rating_stars") %>%
  group_by(isbn, title, author, rating_count) %>%
  summarise(rating_calc = sum(rating_stars * ratings) / sum(ratings),
            rating_eb = sum(rating_stars * (ratings + prior_ratings)) / sum(ratings + prior_ratings)) %>%
  ungroup()
```


### Animations

```{r books-shrunk-data, message = FALSE}
books_shrunk <- books_eb %>%
  filter(rating_count > 0) %>%
  select(isbn:author, rating_count, rating_calc, rating_eb) %>%
  pivot_longer(rating_calc:rating_eb, names_to = "rating_type", values_to = "rating") %>%
  mutate(rating_type = ifelse(rating_type == "rating_calc", "Original Rating", "Empirical Bayes Rating"))
```

```{r animation-all-ratings, fig.align = 'center', fig.width = 8, fig.asp = 0.7}
# Create base plot
p <- books_shrunk %>%
  ggplot(aes(rating_count, rating, col = rating_count)) +
  geom_point(alpha = 0.2) +
  geom_hline(yintercept = par_mean,
             lty = 2,
             size = 1,
             col = "red") +
  scale_colour_fish(option = "Ostracion_whitleyi", trans = "log") +
  scale_x_log10(labels = label_comma(accuracy = 1),
                breaks = 10 ^ c(0:5)) +
  labs(subtitle = "Dashed line shows Bayesian prior for a book with 0 ratings",
       x = "Number of ratings",
       y = "Rating") +
  theme(legend.position = "none",
        text = element_text(family = "Bahnschrift"),
        plot.title = element_text(size = 18),
        axis.text = element_text(size = 16),
        panel.grid.minor.x = element_blank())

# Set animation parameters
anim <- p +
  transition_states(rating_type,
                    transition_length = 1.5,
                    state_length = 2) +
  ease_aes("cubic-in-out") +
  ggtitle("{closest_state}")

# Create animation
anim
```

```{r animation-200-ratings-or-less, fig.align = 'center', fig.width = 8, fig.asp = 0.7}
# Create base plot
p_filtered <- books_shrunk %>%
  filter(rating_count <= 200) %>%
  ggplot(aes(rating_count, rating, col = rating_count)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = par_mean,
             lty = 2,
             size = 1,
             col = "red") +
  scale_colour_fish(option = "Ostracion_whitleyi") +
  scale_x_continuous(breaks = seq(0, 200, by = 25)) +
  labs(subtitle = paste0("Dashed line shows Bayesian prior for a book with 0 ratings",
                        "\n",
                        "(Only books with 200 ratings or less shown)"),
       x = "Number of ratings",
       y = "Rating") +
  theme(legend.position = "none",
        text = element_text(family = "Bahnschrift"),
        plot.title = element_text(size = 18),
        axis.text = element_text(size = 16),
        panel.grid.minor.x = element_blank())

# Set animation parameters
anim_filtered <- p_filtered +
  transition_states(rating_type,
                    transition_length = 1.5,
                    state_length = 1.5) +
  ease_aes("cubic-in-out") +
  ggtitle("{closest_state}")

# Create animation
anim_filtered
```

```{r shrinkage-amount, fig.align = 'center', fig.width = 8, fig.asp = 0.7}
# Amount that the score was changed based on shrinkage
books_eb %>%
  filter(rating_count > 0) %>%
  select(isbn:author, rating_count, rating_calc, rating_eb) %>%
  filter(rating_count <= 200) %>%
  mutate(rating_change = rating_eb - rating_calc) %>%
  ggplot(aes(rating_count, rating_change, col = rating_count)) +
  geom_point(alpha = 0.2) +
  geom_hline(yintercept = 0, lty = 2, size = 1, col = "grey30") +
  scale_colour_fish(option = "Oncorhynchus_keta") +
  expand_limits(y = c(-1, 2)) +
  scale_x_continuous(breaks = seq(0, 200, by = 25)) +
  scale_y_continuous(breaks = seq(-1, 2, by = 0.5)) +
  labs(title = "Fewer Ratings = More Shrinkage",
       subtitle = paste0("As books get more ratings, our Bayesian prior has less influence",
                         "\n",
                         "(This one is not an animation!)"),
       x = "Number of ratings",
       y = "Change in rating from shrinkage") +
  theme(legend.position = "none",
        text = element_text(family = "Bahnschrift"),
        plot.title = element_text(size = 18),
        axis.text = element_text(size = 16),
        panel.grid.minor.y = element_blank())
```




## Scaling

Force it into a normal distribution using ordered quantile normalization, then re-scale from 1 to 5:

- Rankings are preserved (so the top-rated book will remain the top-rated book and the book with, say, the 455th-highest rating stays as the 455th-highest rated book)
- Score changes to fit a normal distribution (why is normal distribution desirable? It is symmetrical and it concentrates books around the mean, so most books are around average, but you get a few exceptionally good and exceptionally bad books)

```{r normalize-and-rescale}
# Use bestNormalize package for ordered quantile normalization
orq_model <- bestNormalize::orderNorm(books_eb$rating_eb, warn = FALSE)

# Create tibble with normalized fitted values
normalized <- tibble(rating_norm = predict(orq_model, newdata = books_eb$rating_eb))

# Add normalized rating to original data and rescale to be 1-5
scaled <- bind_cols(books_eb, normalized) %>%
  mutate(scaled_eb = rescale(rating_eb, to = c(1, 5)),
         scaled_norm = rescale(rating_norm, to = c(1, 5)))

```

```{r animation-scaling, fig.align = 'center', fig.width = 8, fig.asp = 0.7}
# Calculate mean for graphing
scaled_mean <- mean(scaled$scaled_norm)

# Get data in format to be animated
scaled_anim <- scaled %>%
  select(isbn, scaled_eb, scaled_norm) %>%
  pivot_longer(-isbn, names_to = "scale", values_to = "rating") %>%
  mutate(scale = ifelse(scale == "scaled_eb", "Non-Normalized Rating", "Normalized Rating"))

# Create base plot
p_scaling <- scaled_anim %>%
  ggplot(aes(rating)) +
  geom_histogram(binwidth = 0.1, fill = "#778DA9", alpha = 0.8) +
  labs(subtitle = "Normalization squeezes some higher ratings down, filling out the left of the distribution",
       x = "Scaled star rating",
       y = "Number of books") +
  theme(text = element_text(family = "Bahnschrift"),
        plot.title = element_text(size = 18),
        axis.text = element_text(size = 16),
        panel.grid.minor.y = element_blank())

# Set animation parameters
anim_scaling <- p_scaling +
  transition_states(scale,
                    transition_length = 1.5,
                    state_length = 1.5) +
  shadow_mark(past = TRUE, future = TRUE, alpha = 0.2) +
  ggtitle("{previous_state}")

# Create animation
anim_scaling
```



Explanation of how normalizing is a judgement call and that even though we change some of the rating data, we benefit from increased interpretability (mean rating of 3 and equal proportion of books above and below that).



## Additional Stuff

Additional things we could do:

- Apply to different genres
- Extend the model to, e.g., account for books with more ratings probably being higher-rated or certain authors/publishers having higher/lower ratings